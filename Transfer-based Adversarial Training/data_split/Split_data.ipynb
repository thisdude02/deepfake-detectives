{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeyjGfg08AG5",
        "outputId": "5fd4d483-4d05-4eb3-a0f6-a8e9d686a57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCCuK96Mm0Df",
        "outputId": "20503831-35e6-4636-a628-7b72378247d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Installation\n",
        "!pip install pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc5-5lIum24p"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Input your own folder paths to the adversarial videos here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Folder paths: # Replace with your own file paths\n",
        "ORIG_DIRS = [\n",
        "    \"/content/drive/MyDrive/faceforensics++/original_sequences/actors/c40/videos\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/original_sequences/youtube/c40/videos\"\n",
        "]\n",
        "MANIP_DIRS = [\n",
        "    \"/content/drive/MyDrive/faceforensics++/manipulated_sequences/DeepFakeDetection/c40/videos\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/manipulated_sequences/Deepfakes/c40/videos\"\n",
        "]\n",
        "ADV_DIR = \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM\"\n",
        "ADV_DFD_DIR = os.path.join(ADV_DIR, \"VGGFace2/InceptionResnetV1/DeepFakeDetection/Epsilon0.05\")\n",
        "ADV_DF_DIR = os.path.join(ADV_DIR, \"VGGFace2/InceptionResnetV1/Deepfakes/Epsilon0.05\")\n",
        "ADV_DIRS = [\n",
        "    # DFD\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/ImageNet/MobileNet/DeepFakeDetection/Epsilon0.01\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/ImageNet/MobileNet/DeepFakeDetection/Epsilon0.05\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/ImageNet/MobileNet/DeepFakeDetection/Epsilon0.1\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/VGGFace2/InceptionResnetV1/DeepFakeDetection/Epsilon0.01\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/VGGFace2/InceptionResnetV1/DeepFakeDetection/Epsilon0.05\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/VGGFace2/InceptionResnetV1/DeepFakeDetection/Epsilon0.1\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/DeepfakeDetector/UntargettedAttacks/ResNext_LTSM_sequence/DeepFakeDetection/Epsilon0.01\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/DeepfakeDetector/UntargettedAttacks/ResNext_LTSM_frame/DeepFakeDetection/Epsilon0.01\",\n",
        "\n",
        "    # DF\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/ImageNet/MobileNet/Deepfakes/Epsilon0.01\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/ImageNet/MobileNet/Deepfakes/Epsilon0.05\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/ImageNet/MobileNet/Deepfakes/Epsilon0.1\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/VGGFace2/InceptionResnetV1/Deepfakes/Epsilon0.01\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/VGGFace2/InceptionResnetV1/Deepfakes/Epsilon0.05\",\n",
        "    \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM/VGGFace2/InceptionResnetV1/Deepfakes/Epsilon0.1\"\n",
        "]\n",
        "\n",
        "\n",
        "BASELINE_OUTPUT_DIR = \"/content/drive/MyDrive/deepfake_detection_project/Dataset_split/baseline_splits\"\n",
        "ADV_OUTPUT_DIR = \"/content/drive/MyDrive/deepfake_detection_project/Dataset_split/adversarial_splits\"\n",
        "\n",
        "os.makedirs(BASELINE_OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(ADV_OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "\n",
        "# List video files\n",
        "def list_videos(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"path not found {path}\")\n",
        "        return []\n",
        "    return [os.path.join(path, f) for f in os.listdir(path) if f.lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\"))]\n",
        "\n",
        "\n",
        "# Extract video IDs for matching\n",
        "def get_video_id(filename):\n",
        "    base = os.path.basename(filename).split('.')[0]\n",
        "    if '__' in base:  # DFD format\n",
        "        parts = base.split('__')\n",
        "        if len(parts) >= 3:\n",
        "            return parts[0].split(\"_\")[0] + \"__\" + parts[2] \n",
        "        else:\n",
        "            return base\n",
        "        \n",
        "    elif '_' in base:  # DF format\n",
        "        parts = base.split('_')\n",
        "        if len(parts) >= 2:\n",
        "            return f\"{parts[0]}_{parts[1]}\"  \n",
        "        else:\n",
        "            return base\n",
        "        \n",
        "    else:  # original \n",
        "        return base\n",
        "\n",
        "\n",
        "# Find adversarial files that are minimal (must appear in all adversarial folders)\n",
        "def find_adv_intersection():\n",
        "    dfd_files = set(os.path.basename(f) for f in list_videos(ADV_DFD_DIR))\n",
        "    df_files = set(os.path.basename(f) for f in list_videos(ADV_DF_DIR))\n",
        "    return list(dfd_files.union(df_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then begin the splitting of data here, which ensures no leakage of data by closely examinating video relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ub4P1mQmo40"
      },
      "outputs": [],
      "source": [
        "# Main splitting logic\n",
        "def create_splits():\n",
        "    # Adversarial splits\n",
        "    dfd_files = list_videos(ADV_DFD_DIR)\n",
        "    df_files = list_videos(ADV_DF_DIR)\n",
        "    all_adv_files = []\n",
        "    for d in ADV_DIRS:\n",
        "        all_adv_files.extend(list_videos(d))\n",
        "\n",
        "    print(\"adv vid count:\", len(all_adv_files))\n",
        "\n",
        "    # Keep only the intersection by filename\n",
        "    dfd_bases = {os.path.basename(f) for f in dfd_files}\n",
        "    df_bases = {os.path.basename(f) for f in df_files}\n",
        "    intersection_bases = list(dfd_bases | df_bases)  # union\n",
        "\n",
        "    random.shuffle(intersection_bases)\n",
        "\n",
        "    # Split 334/67/67 for adversarial\n",
        "    adv_train_ones = intersection_bases[:100]\n",
        "    adv_val_ones = intersection_bases[100:120]\n",
        "    adv_test_ones = intersection_bases[120: 151]\n",
        "\n",
        "\n",
        "    # Filter full paths to keep only intersection videos\n",
        "    adv_train = [f for f in all_adv_files if os.path.basename(f) in adv_train_ones]\n",
        "    adv_val =  [f for f in all_adv_files if os.path.basename(f) in adv_val_ones]\n",
        "    adv_test = [f for f in all_adv_files if os.path.basename(f) in adv_test_ones]\n",
        "\n",
        "    adv_train = adv_train[:334]\n",
        "    adv_val = adv_val[:67]\n",
        "    adv_test = adv_test[:67]\n",
        "\n",
        "    # print(\"adv_train\", len(adv_train))\n",
        "    # print(\"adv_val\", len(adv_val))\n",
        "    # print(\"adv_test\", len(adv_test))\n",
        "\n",
        "\n",
        "    # Load all original and manipulated files\n",
        "    orig_files = []\n",
        "    for d in ORIG_DIRS:\n",
        "        orig_files.extend(list_videos(d))\n",
        "    manip_files = []\n",
        "    for d in MANIP_DIRS:\n",
        "        manip_files.extend(list_videos(d))\n",
        "\n",
        "    # Shuffle for randomness\n",
        "    random.shuffle(orig_files)\n",
        "    random.shuffle(manip_files)\n",
        "\n",
        "    # Prevent training data(manipulated vids) leaking into test/val\n",
        "    adv_test_ids = {get_video_id(f) for f in adv_test}\n",
        "    adv_val_ids = {get_video_id(f) for f in adv_val}\n",
        "    adv_train_ids = {get_video_id(f) for f in adv_train}\n",
        "    baseline_train_manip = [f for f in manip_files[:500] if get_video_id(f) not in adv_test_ids and get_video_id(f) not in adv_val_ids]\n",
        "    baseline_val_manip = [f for f in manip_files[500:600] if get_video_id(f) not in adv_test_ids and get_video_id(f) not in adv_train_ids]\n",
        "    baseline_test_manip = [f for f in  manip_files[600:700] if get_video_id(f) not in adv_train_ids and get_video_id(f) not in adv_val_ids]\n",
        "\n",
        "    # Check once more that training data (original) do not leak into test/val\n",
        "    mani_test_ids = {get_video_id(f) for f in baseline_test_manip}\n",
        "    mani_val_ids = {get_video_id(f) for f in baseline_val_manip}\n",
        "    mani_train_ids = {get_video_id(f) for f in baseline_train_manip}\n",
        "    baseline_train_orig = [f for f in orig_files[:500] if get_video_id(f) not in (adv_test_ids | mani_test_ids) and get_video_id(f) not in (adv_val_ids | mani_val_ids)]\n",
        "    baseline_val_orig = [f for f in orig_files[500:600] if get_video_id(f) not in (adv_test_ids | mani_test_ids) and get_video_id(f) not in (adv_train_ids | mani_train_ids)]\n",
        "    baseline_test_orig = [f for f in  orig_files[600:700] if get_video_id(f) not in (adv_train_ids | mani_train_ids) and get_video_id(f) not in (adv_val_ids | mani_val_ids)]\n",
        "\n",
        "    baseline_train = baseline_train_manip + baseline_train_orig\n",
        "    baseline_val = baseline_val_manip + baseline_val_orig\n",
        "    baseline_test = baseline_test_manip + baseline_test_orig\n",
        "\n",
        "    # print(len(adv_train))\n",
        "\n",
        "    adv_train.extend(baseline_train_manip[:333] + baseline_train_orig[:333])\n",
        "    adv_val.extend(baseline_val_manip[:67] + baseline_val_orig[:67])\n",
        "    adv_test.extend(baseline_test_manip[:67] + baseline_test_orig[:67])\n",
        "\n",
        "\n",
        "    # print(adv_train)\n",
        "\n",
        "\n",
        "    print(f\"Adv split counts → train: {len(adv_train)}, val: {len(adv_val)}, test: {len(adv_test)}\")\n",
        "\n",
        "    return {\n",
        "        'baseline': (baseline_train, baseline_val, baseline_test),\n",
        "        'adv': (adv_train, adv_val, adv_test)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save splits into txt files and print the split summary\n",
        "def save_list(path, lst):\n",
        "    with open(path, 'w') as f:\n",
        "        f.write('\\n'.join(lst))\n",
        "    print(f\"Saved → {path} ({len(lst)} items)\")\n",
        "\n",
        "def save_splits(splits):\n",
        "    baseline_train, baseline_val, baseline_test = splits['baseline']\n",
        "    adv_train, adv_val, adv_test = splits['adv']\n",
        "\n",
        "    # Save baseline\n",
        "    save_list(os.path.join(BASELINE_OUTPUT_DIR, \"train.txt\"), baseline_train)\n",
        "    save_list(os.path.join(BASELINE_OUTPUT_DIR, \"val.txt\"), baseline_val)\n",
        "    save_list(os.path.join(BASELINE_OUTPUT_DIR, \"test.txt\"), baseline_test)\n",
        "\n",
        "    # Save adversarial\n",
        "    save_list(os.path.join(ADV_OUTPUT_DIR, \"train.txt\"), adv_train)\n",
        "    save_list(os.path.join(ADV_OUTPUT_DIR, \"val.txt\"), adv_val)\n",
        "    save_list(os.path.join(ADV_OUTPUT_DIR, \"test.txt\"), adv_test)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n=== BASELINE SPLIT ===\")\n",
        "    print(f\"train: {len(baseline_train)}\")\n",
        "    print(f\"val:   {len(baseline_val)}\")\n",
        "    print(f\"test:  {len(baseline_test)}\")\n",
        "    print(\"\\n=== ADVERSARIAL SPLIT ===\")\n",
        "    print(f\"train: {len(adv_train)}\")\n",
        "    print(f\"val:   {len(adv_val)}\")\n",
        "    print(f\"test:  {len(adv_test)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    splits = create_splits()\n",
        "    save_splits(splits)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
