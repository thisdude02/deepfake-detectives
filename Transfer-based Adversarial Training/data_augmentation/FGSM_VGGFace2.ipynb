{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer FGSM attack generator - Surrogate Model: InceptionResnetV1 (VGGFace2)"
      ],
      "metadata": {
        "id": "KnM2fHWmS3zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRllNwJpAoqW",
        "outputId": "029366ff-2e19-41b3-a0f0-5362c9b34bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpl.rcParams['figure.figsize'] = (8, 8)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "metadata": {
        "id": "13K8cKewCvMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Koc7AwnrFPU",
        "outputId": "9fc6e21c-f470-433c-bd03-2ee9d7b5f3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.32.4)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ib-r7SoA2ar"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the surrogate model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mtcnn = MTCNN(keep_all=True, device=device)\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
      ],
      "metadata": {
        "id": "v0439Eq-TsnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "def clip_box(box, W, H):\n",
        "    x1, y1, x2, y2 = box\n",
        "    x1 = max(0, min(W-1, x1))\n",
        "    x2 = max(0, min(W-1, x2))\n",
        "    y1 = max(0, min(H-1, y1))\n",
        "    y2 = max(0, min(H-1, y2))\n",
        "    return int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "\n",
        "def preprocess_face(face_rgb):\n",
        "    face = cv2.resize(face_rgb, (160,160))\n",
        "    face = torch.tensor(face/255.0, dtype=torch.float32).permute(2,0,1)\n",
        "    return face.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "def fgsm_face(face_rgb, epsilon):\n",
        "    x = preprocess_face(face_rgb)\n",
        "    x.requires_grad = True\n",
        "\n",
        "    emb = model(x)\n",
        "    loss = emb.norm()\n",
        "    loss.backward()\n",
        "\n",
        "    grad = x.grad.data\n",
        "    adv = x + epsilon * grad.sign()\n",
        "    adv = torch.clamp(adv, 0, 1)\n",
        "\n",
        "    adv_np = adv[0].permute(1,2,0).detach().cpu().numpy()\n",
        "    adv_np = (adv_np * 255).astype(np.uint8)\n",
        "\n",
        "    return adv_np\n",
        "\n",
        "\n",
        "def paste_face(orig_rgb, adv_face, clipped_box):\n",
        "    x1, y1, x2, y2 = clipped_box\n",
        "    H = y2 - y1\n",
        "    W = x2 - x1\n",
        "\n",
        "    adv_resized = cv2.resize(adv_face, (W, H))\n",
        "    patched = orig_rgb.copy()\n",
        "    patched[y1:y2, x1:x2] = adv_resized\n",
        "    return patched\n",
        "\n",
        "\n",
        "def fgsm_video(input_path, output_path, epsilon=0.01, frames_to_attack=70):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    video_name = os.path.basename(input_path)\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (W, H))\n",
        "\n",
        "    detected_any_face = False\n",
        "\n",
        "    count = 0\n",
        "    while count < frames_to_attack:\n",
        "        ret, frame_bgr = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "        boxes, _ = mtcnn.detect(rgb)\n",
        "\n",
        "        if boxes is None:\n",
        "            out.write(frame_bgr)\n",
        "            count += 1\n",
        "            continue\n",
        "\n",
        "        detected_any_face = True\n",
        "\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            cx1, cy1, cx2, cy2 = clip_box((x1, y1, x2, y2), W, H)\n",
        "\n",
        "            if cx2 <= cx1 or cy2 <= cy1:\n",
        "                continue\n",
        "\n",
        "            face = rgb[cy1:cy2, cx1:cx2]\n",
        "            if face.size == 0:\n",
        "                continue\n",
        "\n",
        "            adv_face = fgsm_face(face, epsilon)\n",
        "            rgb = paste_face(rgb, adv_face, (cx1, cy1, cx2, cy2))\n",
        "\n",
        "        adv_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
        "        out.write(adv_bgr)\n",
        "        count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    if not detected_any_face: # Make sure that vids without detecting a face throughout is considered invalid\n",
        "        print(f\"No face detected in entire video: {video_name}\")\n"
      ],
      "metadata": {
        "id": "3yupgw9d1YOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTIBOq1FDRhN"
      },
      "outputs": [],
      "source": [
        "# src and dst folders (Change it to your path for the manipulated videos and where you want to store the resultant videos)\n",
        "src_dir = \"/content/drive/MyDrive/faceforensics++/manipulated_sequences/Deepfakes/c40/videos/\"\n",
        "output_dir = \"/content/drive/MyDrive/faceforensics++/Adversarial_attacked_sequences/TransferAttacks/FGSM//VGGFace2/InceptionResnetV1/Deepfakes/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXl1f2PPULVF"
      },
      "outputs": [],
      "source": [
        "def FGSM(epsilon):\n",
        "    outdir = os.path.join(output_dir, f\"Epsilon{epsilon}\")\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    for video_path in tqdm(glob.glob(os.path.join(src_dir, \"*.mp4\"))):\n",
        "        fname = os.path.basename(video_path)\n",
        "        save_path = os.path.join(outdir, fname)\n",
        "\n",
        "        if os.path.exists(save_path):\n",
        "            continue\n",
        "\n",
        "        fgsm_video(video_path, save_path, epsilon)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hguSym6o4oCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f568e86c-539b-438b-8c8c-a93cab40d255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–Œ         | 54/1000 [10:35<3:09:56, 12.05s/it]"
          ]
        }
      ],
      "source": [
        "FGSM(0.1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}